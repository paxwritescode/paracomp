\section{Постановка задачи и её формализация}
\label{sec:problem_statement}
Дана система линейных неоднородных обыкновенных дифференциальных уравнений с постоянными коэффициентами:
\begin{equation}
	\label{eq:main_system}
	\frac{d \boldsymbol{y}}{dt} = A \boldsymbol{y} + \boldsymbol{f}(t),
\end{equation}
и следующими начальными условиями:
\begin{equation}
	\label{eq:init_cond}
	y_i = 1, \quad i = \overline{1, n}.
\end{equation}
Здесь $\boldsymbol{y}(t) = 
\begin{pmatrix}
	y_1(t) \\
	y_2(t) \\
	\cdots \\
	y_n(t)
\end{pmatrix}$, 
$\boldsymbol{f}(t) = 
\begin{pmatrix}
	f_1(t) \\
	f_2(t) \\
	\cdots \\
	f_n(t)
\end{pmatrix}$, 
матрица $A$ имеет размерность $n \times n$ и является верхнетреугольной 
($a_{ij} = 0 \text{ при } i < j)$ с единичными ненулевыми элементами.

Необходимо решить задачу методом последовательных приближений Пикара с применением циклической схемы распределения уравнений по процессам для обеспечения равномерной загрузки процессоров, осуществляя программирование на языке C с применением технологии OpenMP. Также требуется провести анализ метода путём следующих исследований:
\begin{itemize}
	\item зависимость времени выполнения от размера системы;
	\item зависимость времени выполнения от числа параллельных процессов/потоков;
	\item зависимость ускорения от числа параллельных процессов/потоков;
	\item зависимость эффективности параллелизации от числа параллельных процессов/потоков.
\end{itemize}

\section{Алгоритм метода Пикара и условия его применимости}
\subsection{Описание метода}
Метод Пикара для задачи~\eqref{eq:main_system} с начальными условиями~\eqref{eq:init_cond} определяет последовательность приближений $\boldsymbol{y}^{(k)}(t)$ следующим образом:
\begin{equation*}
	\boldsymbol{y}^{(k + 1)}(t) = \boldsymbol{y}_0 
	+ \int_{t_0}^t \left( A \boldsymbol{y}^{(k)}(\tau) + \boldsymbol{f}(\tau) \right)\, d\tau, 
	\quad k = 0, 1, 2, \dotsc
\end{equation*}
Процесс продолжается до выполнения критерия сходимости:
\begin{equation*}
	\left\| \boldsymbol{y}^{(k + 1)} - \boldsymbol{y}^{(k)} \right\| < \varepsilon
\end{equation*}
Интеграл вычисляется численно по квадратурной формуле трапеций на каждом временном интервале $[t_m, t_{m + 1}]$:
\begin{equation}
	\boldsymbol{y}^{(k + 1)}_{m + 1} = \boldsymbol{y}_m^{(k + 1)} + \frac{\Delta t}{2} \left[ A \boldsymbol{y}_m^{(k)} + \boldsymbol{f}(t_m) + A \boldsymbol{y}^{(k)}_{m + 1} + \boldsymbol{f}(t_{m + 1)})
	\right],
\end{equation}
где $\Delta t = t_{m + 1} - t_m, \ \boldsymbol{y}_m^{(k)}$ - приближение в узле $t_m$ на $k$-й итерации.
\subsection{Параллелизация вычислений}
На каждой итерации вычисления правых частей для разных компонент системы независимы, так как они используют значения предыдущего приближения $\boldsymbol{y}^{(k)}$, которые на этом этапе полностью известны. Поэтому в данной задаче применяется декомпозиция по данным (parallelism across space). При таком способе работы каждая компонентная функция $y_i(t)$ считается независимо, уравнения равномерно распределяются между потоками OpenMP. Используется циклическая схема распределения.\\
Каждый поток независимо выполняет:
\begin{enumerate}
	\item вычисление своих компонент $$A\boldsymbol{y}^{(k)} + \boldsymbol{f}(t),$$
	\item применение квадратурной формулы трапеций для этих компонент.
\end{enumerate}
Синхронизация необходима только между итерациями $k$ и $k + 1$, когда все потоки должны завершить обновление своих компонент.
\subsection{Условия применимости метода}
Итерационный процесс Пикара сходится при выполнении следующих условий:
\begin{enumerate}
	\item липшицевость правой части по переменной $y$;
	\item ограниченность интервала интегрирования;
	\item корректность задания начальных условий.
\end{enumerate}
\subsection{Стандарт OpenMP}
OpenMP (от англ. Open Multi-Processing) - открытый стандарт для распараллеливания программ на языках C, C++ и Fortran, дающий описание совокупности директив компилятора, библиотечных процедур и переменных окружения, предназначенных для программирования многопоточных приложений на многопроцессорных системах с общей памятью.
\section{Предварительный анализ задачи (проверка условий применимости метода)}
\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{fig/Liepschitz_cond}
\end{figure}
\section{Тестовый пример с детальными расчётами для задачи малой размерности}
\label{sec:test_example}
Рассмотрим первые две итерации метода Пикара для задачи размерности 3.
\includepdf[pages=-]{Test_example_lab1.pdf}
\section{Подготовка контрольных тестов для иллюстрации метода}
\label{sec:description_of_data}
Во всех исследованиях правая часть СЛАУ имеет вид $\boldsymbol{f}(t) = sin(t + i), \: i = \overline{(0, n - 1)}$. \\

Для исследования зависимости времени выполнения программы от размера системы зафиксируем количество потоков $p = 4$, а также количество узлов $m = 1000$. Будем поочерёдно запускать метод на системах размерности от 1 до 30.\\

В исследованиях времени выполнения, ускорения и эффективности параллелизации от количества параллельных процессов будем брать поочерёдно значения количества потоков $p$ от 1 до 12, количество потоков ограничивается количеством ядер процессора, равным 6. Зафиксируем размерность системы $n = 1000$ и количество узлов $m = 3500$, данные значения обеспечивают достаточную вычислительную нагрузку для проявления эффекта параллелизации. \\

Ускорение находится по формуле $a = \frac{T_1}{T_p}$, где ${T_1}$ - время выполнения программы без параллелизации, ${T_p}$ - время выполнения при числе потоков $p$. Эффективность параллелизации вычисляется по формуле $E = \frac{T_1}{p \cdot T_p}$.
\section{Модульная структура программы}
\lstinputlisting[
basicstyle=\ttfamily\small,
frame=single,
breaklines=true,
label={lst:project-tree}
]{../../code/structure.txt}

Приведём на \hyperref[lst:project-tree]{листинге} дерево проекта.\\
В файле \texttt{analysis/plots.ipynb} содержится код чтения данных из \texttt{.csv} файлов и построение графиков средствами \texttt{matplotlib.pyplot}.\\
Опишем  файлы из директории \texttt{src}, где содержится \texttt{C}-код метода.
\begin{itemize}
	\item \texttt{matrix\_tools.c}
	\begin{itemize}
		\item \texttt{double **alloc\_matrix(int n, int m)} - выделение памяти для матрицы размера $n \times m$;
		\item \texttt{void free\_matrix(double **y, int n)} - освобождение памяти, занятой массивом из $n$ массивов;
		\item \texttt{double compute\_diff\_norm(int n, int m, double **y1, double **y2)} - вычисление строковой максимум-нормы разности матриц;
		\item \texttt{void matrix\_mul\_vector(int n, double** A, double* y\_m, double* res)} - умножение матрицы на вектор.
	\end{itemize}
	\item \texttt{picard.c}
	\begin{itemize}
		\item \texttt{double **picard\_method(int n, double **f, double**A, double eps, double t\_0, double t, int m)} - функция метода Пикара для задачи размерности \texttt{n} c \texttt{m} узлами, матрицей \texttt{A} и вектором правой части \texttt{f} на отрезке $[t_0, t]$ с точностью \texttt{eps}.
	\end{itemize}
	\item \texttt{generate.c}
	\begin{itemize}
		\item \texttt{double **generate\_test\_rhs(int n, int m, double t\_0, double t)} - генерация правой части для \hyperref[sec:test_example]{тестового примера};
		\item \texttt{double **generate\_rhs(int n, int m, double t\_0, double t)} - генерация правой части для контрольного примера;
		\item \texttt{int generate\_threads(int *threads, int max\_threads)} - генерация последовательности чисел от \texttt{1} до \texttt{max\_threads} и её сохранение;
		\item \texttt{double **generate\_matrix(int n)} - генерация матрицы для контрольного примера согласно \hyperref[sec:problem_statement]{постановке задачи}.
	\end{itemize}
	\item \texttt{study.c}
	\begin{itemize}
		\item \texttt{void study\_time\_vs\_size(void)} - изучение зависимости времени выполнения программы от разных значений размерности системы. Функция перебирает значения размерности от 1 до 30 при фиксированном количестве потоков и записывает время выполнения программы для каждого значения размерности в \texttt{.csv}-файл для построения графика;
		\item \texttt{void study\_dependencies\_on\_threads(void)} - изучение зависимости времени выполнения программы, ускорения и эффективности параллелизации от числа параллельных процессов. Функция фиксирует размерность системы и число узлов и решает задачу методом Пикара для каждого значения числа параллельных процессов, вычисляя все перечисленные выше величины и записывая их в \texttt{.csv}-файл.
	\end{itemize}
	\item \texttt{main.c}
	\begin{itemize}
		\item \texttt{void run\_test\_case(void)} - функция исполнения \hyperref[sec:test_example]{тестового примера} для проверки корректности реализации метода;
		\item \texttt{int main(void)} - запуск функций из \texttt{study.c}.
	\end{itemize}
\end{itemize}
\section{Численный анализ решения задачи}
Значения фиксированных переменных и диапазоны меняющихся для описанных ниже исследований приведены \hyperref[sec:description_of_data]{выше}. \\

На \autoref{fig:timevssize} показан график зависимости времени выполнения программы от размерности системы. %при 4 потоках OpenMP и 1000 узлах.\\
\begin{figure}
	\centering
	\includegraphics[width=0.75\linewidth]{../../code/picard/results/time_vs_size}
	\caption{Зависимость времени исполнения программы от размерности системы при 4 потоках}
	\label{fig:timevssize}
\end{figure}
Из графика видно, что время выполнения программы с ростом размерности системы возрастает квадратично, что обусловлено квадратичной вычислительной сложностью операций умножения матрицы на вектор на каждом шаге метода Пикара. Параллельная реализация с использованием четырёх потоков позволяет сократить абсолютное время выполнения программы, но не меняет характер зависимости. Небольшие неровности на графике связаны с особенностями работы с памятью и накладными расхоодами параллельных вычислений. \\

%Во всех последующих исследованиях фиксированы размерность системы ($n = 1000$) и число узлов ($m = 3500$).

График зависимости времени выполнения программы от числа параллельных процессов показан на \autoref{fig:timevsthreads}.\\

Согласно графику, при увеличении числа потоков от 1 до 4-5 наблюдается существенное сокращение времени исполнения программы. При дальнейшем увеличении числа потоков снижение времени замедляется и, более того, возможно нго увеличение. Это связано с ростом накладных расходов на синхронизацию потоков и работу с памятью.
\begin{figure}
	\centering
	\includegraphics[width=0.75\linewidth]{../../code/picard/results/time_vs_threads}
	\caption{Зависимость времени исполнения программы от числа параллельных процессов}
	\label{fig:timevsthreads}
\end{figure}

На \autoref{fig:speedupvsthreads} представлен график ускорения в зависимости от числа параллельных процессов/потоков. Ускорение растёт практически линейно при числе потоков до 4-5, максимальное ускорение составляет около 4.1-4.2 и достигается при 11 потоках. Нелинейный характер роста ускорения и наличие локальных провалов обусловлены накладными расходами OpenMP и конкуренцией потоков за доступ к памяти.
\begin{figure}
	\centering
	\includegraphics[width=0.75\linewidth]{../../code/picard/results/speedup_vs_threads}
	\caption{Зависимость ускорения от числа параллельных процессов}
	\label{fig:speedupvsthreads}
\end{figure}

График эффективности параллелизации от числа потоков приведён на \autoref{fig:efficiencyvsthreads}. Можно видеть, что при увеличении числа потоков накладные расходы и ограничения архитектуры начинают доминировать, в связи с этим жффективность параллелизации с ростом числа потоков снижается. Однако при малом числе потоков наблюдается небольшой рост эффективности.
\begin{figure}
	\centering
	\includegraphics[width=0.75\linewidth]{../../code/picard/results/efficiency_vs_threads}
	\caption{Зависимость эффективности параллелизации от числа параллельных процессов}
	\label{fig:efficiencyvsthreads}
\end{figure}


\section{Выводы}
В ходе выполнения данной работы была реализована параллельная версия метода Пикара с применением циклической схемы распределения уравнений по процессам с использованием технологии OpenMP, а также проведён ряд вычислительных экспериментов. \\

Исследования показали, что с ростом размерности системы время выполнения программы возрастает квадратично. Такой характер роста обусловлен квадратичной вычислительной сложностью операции умножения матрицы на вектор.\\

При увеличении числа потоков наблюдается существенное сокращение времени выполнения программы по сравнению с её последовательным исполнением. Наибоольший выигрыш достигается при увеличении числа потоков до значения, близкого к числу вычислительных ядер компьютера. Дальнейшее увеличение числа потоков не приводит к заметному сокращению исполняемого времени вследствие роста накладных расходов и ограничений архитектуры памяти.\\

Анализ ускорения показал, что при малом числе потоков наблюдается близкий к линейному рост ускорения, однако при числе потоков, большем 5, ускорение практически останавливается.\\

Эффективность параллелизации незначительно растёт при малом числе потоков, но при его дальнейшем увеличении эффективность снижается вследствие роста накладных расходов на синхронизацию и конкуренции за ресурсы.\\

Таким образом, параллельная реализация метода Пикара позволяет существенно сократить время исполнения для задач большой размерности.
\section{Примечания}
Код реализации метода доступен \href{https://github.com/paxwritescode/paracomp/tree/master/001-ode-cauchy/code/picard}{здесь}.